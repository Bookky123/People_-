{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy -q"
      ],
      "metadata": {
        "id": "YtP1N3yu3__d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQNXWgAvABau"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/DATA_all()/people_all.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "_LWpUJE49c3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4SfGGtW_AWrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "id": "ln3j3uv9AWuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "metadata": {
        "id": "HyuCRMYYAWwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ทราบข่าวจากไหน\n",
        "follow = df[['social','billboard','news_paper','radio','tv','friend','government','village_leader']]\n",
        "\n",
        "# มางานเพิ่อจุดประสงค์อะไร\n",
        "spend = df[['store','food','activity','art','temple','view']]"
      ],
      "metadata": {
        "id": "i1rm2uGOJckK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ด้านการดำเนินงานของสถานี & การจัดงาน\n",
        "station = df[['c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16']]\n",
        "\n",
        "#ด้านสถานที่เเละสภาพเเวดล้อม\n",
        "environment = df[['c7','c18','c19','c20','c21','c22','c23','c24','c25']]\n",
        "\n",
        "#ด้านร้านค้าเเละอาหาร\n",
        "store = df[['c27','c28','c29','c30','c31']]"
      ],
      "metadata": {
        "id": "LuX7aRMoEqg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_channels = pd.DataFrame(follow)\n",
        "df_preference = pd.DataFrame(spend)"
      ],
      "metadata": {
        "id": "so__4kVTvC85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Data"
      ],
      "metadata": {
        "id": "oVMjTKBFCRDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_row = min(len(df_channels), len(df_preference))\n",
        "df_channels = df_channels.head(min_row)\n",
        "df_preference = df_preference.head(min_row)\n",
        "\n",
        "df_combined = pd.concat([df_channels, df_preference], axis=1)\n",
        "\n",
        "corr_channels = df_channels.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 9)) # ปรับขนาดรูปภาพ\n",
        "sns.heatmap(corr_channels,\n",
        "            annot=True,     # แสดงค่าตัวเลขบน Heatmap\n",
        "            cmap='coolwarm',# เลือกโทนสี (coolwarm: แดง-น้ำเงิน)\n",
        "            fmt=\".2f\",      # แสดงทศนิยม 2 ตำแหน่ง\n",
        "            linewidths=.5,  # เพิ่มเส้นแบ่งระหว่างเซลล์\n",
        "            cbar_kws={'label': 'Pearson Correlation Coefficient'}) # เพิ่มป้ายกำกับแถบสี\n",
        "plt.title('Heatmap: Relation between Perception channels', fontsize=18)\n",
        "plt.xticks(rotation=45, ha='right') # หมุนป้ายแกน X เพื่อให้อ่านง่าย\n",
        "plt.yticks(rotation=0) # ป้ายแกน Y ตั้งตรง\n",
        "plt.tight_layout() # ปรับ layout ให้พอดี\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L7H4HEBjB9EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_row = min(len(df_channels), len(df_preference))\n",
        "df_channels = df_channels.head(min_row)\n",
        "df_preference = df_preference.head(min_row)\n",
        "\n",
        "df_combined = pd.concat([df_channels, df_preference], axis=1)\n",
        "\n",
        "corr_preference = df_preference.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 9)) # ปรับขนาดรูปภาพ\n",
        "sns.heatmap(corr_preference,\n",
        "            annot=True,\n",
        "            cmap='coolwarm',\n",
        "            fmt=\".2f\",\n",
        "            linewidths=.5,\n",
        "            cbar_kws={'label': 'Pearson Correlation Coefficient'})\n",
        "plt.title('Heatmap: Relation betweeen activity/store', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mUREjRczG823"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_row = min(len(df_channels), len(df_preference))\n",
        "df_channels = df_channels.head(min_row)\n",
        "df_preference = df_preference.head(min_row)\n",
        "\n",
        "df_combined = pd.concat([df_channels, df_preference], axis=1)\n",
        "\n",
        "cross_corr = df_channels.corrwith(df_preference) # แต่ละคอลัมน์ของ df_channels เทียบกับแต่ละคอลัมน์ของ df_preferences\n",
        "\n",
        "\n",
        "full_corr_matrix = df_combined.corr()\n",
        "cross_corr_subset = full_corr_matrix.loc[df_channels.columns, df_preference.columns]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 10)) # ปรับขนาดรูปภาพให้ใหญ่ขึ้น เพราะมีจำนวนคอลัมน์เยอะ\n",
        "sns.heatmap(cross_corr_subset, # ใช้ Sub-matrix ที่เลือกมา\n",
        "            annot=True,\n",
        "            cmap='coolwarm',\n",
        "            fmt=\".2f\",\n",
        "            linewidths=.5,\n",
        "            cbar_kws={'label': 'Pearson Correlation Coefficient'})\n",
        "plt.title('Heatmap: Relation between Perception channels & activity/store', fontsize=18)\n",
        "plt.xlabel('activity / store', fontsize=14)\n",
        "plt.ylabel('Perception channel', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWsGoURbGoGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attendees_per_year = df.groupby('year').size()\n",
        "\n",
        "attendees_per_year.plot(kind='bar', color='coral')\n",
        "plt.title('number of Participants each year')\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('number of Participants')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x-UCeCgIPcjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_order = ['<20','21-40','41-60','60>']\n",
        "\n",
        "age_counts = df['age'].value_counts().reindex(age_order)\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "sns.barplot(x=age_counts.index,y=age_counts.values)\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('number of participants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YMd4avq_7HrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "travel_counts = df['travel'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "sns.barplot(x=travel_counts.values,y=travel_counts.index)\n",
        "plt.xlabel('travel')\n",
        "plt.ylabel('number of participants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bzcWSe4PcYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "follow_counts = follow.sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "sns.barplot(x=follow_counts.values,y=follow_counts.index)\n",
        "plt.xlabel('follow news about 66-68')\n",
        "plt.ylabel('number of participants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GzSx_yMaPca0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spend_counts = spend.sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "sns.barplot(x=spend_counts.values,y=spend_counts.index)\n",
        "plt.xlabel('follow news about 66-68')\n",
        "plt.ylabel('number of participants')"
      ],
      "metadata": {
        "id": "K4ukSdCTPcVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choices = df.loc[:, 'c1':'c31']\n",
        "\n",
        "# นับจำนวนที่มีค่า = 1 (แสดงว่า \"พอใจน้อยที่สุด\")\n",
        "choice_counts = (choices == 1).sum().nlargest(5).sort_values(ascending=True)\n",
        "\n",
        "# วาด Horizontal Bar Chart\n",
        "plt.figure(figsize=(8, 10))\n",
        "choice_counts.plot(kind='barh')\n",
        "plt.title('number of Respondent (c1 - c31)')\n",
        "plt.xlabel('number of score')\n",
        "plt.ylabel('choice')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z8QQlksxAWyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choices = df.loc[:, 'c1':'c31']\n",
        "\n",
        "# นับจำนวนที่มีค่า = 5 (แสดงว่า \"พอใจมากที่สุด\")\n",
        "choice_counts = (choices == 5).sum().nlargest(5).sort_values(ascending=True)\n",
        "\n",
        "# วาด Horizontal Bar Chart\n",
        "plt.figure(figsize=(8, 10))\n",
        "choice_counts.plot(kind='barh')\n",
        "plt.title('number of Respondent (c1 - c31)')\n",
        "plt.xlabel('number of score')\n",
        "plt.ylabel('choice')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_XAzANOlAW0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "dpMbQda054ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "_B1YpxATJYee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_channels"
      ],
      "metadata": {
        "id": "mCJ_GQqCu2qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_cols = [f'c{i}' for i in range(21,25)] + [f'c{i}' for i in range(27,31)]\n",
        "\n",
        "for col in score_cols:\n",
        "    if col in df_combined.columns:\n",
        "        # แปลงเป็น numeric หากไม่ใช่ (coerce จะเปลี่ยนค่าที่ไม่สามารถแปลงได้เป็น NaN)\n",
        "        df_combined[col] = pd.to_numeric(df_combined[col], errors='coerce')\n",
        "\n",
        "        # สร้างคอลัมน์ Dummy (0/1) เพื่อระบุว่า 'ไม่แสดงความคิดเห็น' (เดิมเป็น 9)\n",
        "        # ตั้งชื่อคอลัมน์ใหม่ว่า 'col_no_opinion'\n",
        "        df_combined[f'{col}_no_opinion'] = (df_combined[col] == 9).astype(int)\n",
        "\n",
        "        # เปลี่ยนค่า 9 ให้เป็น NaN เพื่อเตรียมการ Imputation หรือเพื่อจัดการแยกต่างหาก\n",
        "        df_combined.loc[df_combined[col] == 9, col] = np.nan\n",
        "\n",
        "        # จัดการค่าที่อยู่นอกช่วง 1-5 ที่อาจเป็นค่าผิดปกติอื่นๆ (ถ้ามี)\n",
        "        df_combined.loc[df_combined[col] > 5, col] = np.nan\n",
        "        df_combined.loc[df_combined[col] < 1, col] = np.nan\n",
        "\n",
        "# 1.2 จัดการค่าที่หายไป (NaN) ในคอลัมน์คะแนน c21-c31 โดยการเติมด้วยค่าเฉลี่ย (Mean Imputation)\n",
        "# หมายเหตุ: ค่าเฉลี่ยนี้จะคำนวณจากเฉพาะค่า 1-5 เท่านั้น เนื่องจากค่า 9 ถูกเปลี่ยนเป็น NaN แล้ว\n",
        "for col in score_cols:\n",
        "    if col in df_combined.columns:\n",
        "        if df_combined[col].isnull().any(): # ตรวจสอบว่ามี NaN อยู่หรือไม่\n",
        "            df_combined[col] = df_combined[col].fillna(df_combined[col].mean())\n"
      ],
      "metadata": {
        "id": "A5FwtTJhqDqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 One-Hot Encoding สำหรับคอลัมน์เชิงหมวดหมู่ที่เป็นข้อความ\n",
        "df['join_next_year'] = df['join_next_year'].replace('no','No').replace('yes','Yes').replace('maybe','Maybe')\n",
        "df['dress'] = df['dress'].replace('no','No').replace('yes','Yes').replace('maybe','Maybe')\n",
        "\n",
        "categorical_cols_to_encode = ['sex', 'age', 'province', 'travel', 'join_next_year', 'dress']\n",
        "df_processed = pd.get_dummies(df, columns=categorical_cols_to_encode, drop_first=True)"
      ],
      "metadata": {
        "id": "2wpRyAkYJc80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Multi-Label Binarization สำหรับ 'preferences_activity_product_raw' (จาก image_d62d18.png / image_d6345c.png)\n",
        "if 'preferences_activity_product_raw' in df_processed.columns:\n",
        "    print(\"\\n--- การแปลง 'preferences_activity_product_raw' (Multi-Label) ---\")\n",
        "    # ทำความสะอาดและแยกข้อความ: แทนที่ '.' ด้วย ',' และลบช่องว่าง ทำเป็นตัวพิมพ์เล็ก\n",
        "    df_processed['preferences_activity_product_raw'] = df_processed['preferences_activity_product_raw'].astype(str).str.replace('.', ',', regex=False).str.replace(' ', '').str.lower()\n",
        "\n",
        "    # ดึงค่าที่ไม่ซ้ำกันทั้งหมดจากทุกเซลล์\n",
        "    all_prefs = df_processed['preferences_activity_product_raw'].str.split(',').explode()\n",
        "    unique_prefs = all_prefs.dropna().unique()\n",
        "\n",
        "    # สร้างคอลัมน์ใหม่สำหรับแต่ละ preference และใส่ 0/1\n",
        "    for pref in unique_prefs:\n",
        "        if pref and pd.notna(pref): # ตรวจสอบว่าไม่ใช่ค่าว่างหรือ NaN\n",
        "            col_name = f'pref_{pref.strip()}' # Trim whitespace\n",
        "            df_processed[col_name] = df_processed['preferences_activity_product_raw'].apply(\n",
        "                lambda x: 1 if pref.strip() in str(x).split(',') else 0\n",
        "            )\n",
        "    # ลบคอลัมน์ preferences_activity_product_raw เดิมออก\n",
        "    df_processed = df_processed.drop(columns=['preferences_activity_product_raw'])\n",
        "    print(\"DataFrame หลังแปลง 'preferences_activity_product_raw':\")\n",
        "    print(df_processed.head())\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 2.3 Multi-Label Binarization สำหรับ 'product_choices_text_raw' (จาก image_f111f8.png)\n",
        "if 'product_choices_text_raw' in df_processed.columns:\n",
        "    print(\"\\n--- การแปลง 'product_choices_text_raw' (Multi-Label) ---\")\n",
        "    # ทำความสะอาดข้อความ: ลบตัวเลขนำหน้าและข้อความในวงเล็บ\n",
        "    df_processed['product_choices_text_raw'] = df_processed['product_choices_text_raw'].astype(str).str.lower().str.replace(r'\\d+\\.', '', regex=True).str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
        "\n",
        "    # แยกด้วยเครื่องหมายจุลภาคและจัดเรียง/ทำความสะอาดเพื่อมาตรฐาน\n",
        "    df_processed['product_choices_text_raw'] = df_processed['product_choices_text_raw'].apply(\n",
        "        lambda x: ','.join(sorted([item.strip() for item in str(x).split(',') if item.strip()]))\n",
        "    )\n",
        "\n",
        "    all_product_choices = df_processed['product_choices_text_raw'].str.split(',').explode()\n",
        "    unique_product_choices = all_product_choices.dropna().unique()\n",
        "\n",
        "    # สร้างคอลัมน์ใหม่สำหรับแต่ละตัวเลือก\n",
        "    for choice in unique_product_choices:\n",
        "        if choice and pd.notna(choice):\n",
        "            col_name = f'product_{choice.strip()}'\n",
        "            df_processed[col_name] = df_processed['product_choices_text_raw'].apply(\n",
        "                lambda x: 1 if choice.strip() in str(x).split(',') else 0\n",
        "            )\n",
        "    # ลบคอลัมน์ product_choices_text_raw เดิมออก\n",
        "    df_processed = df_processed.drop(columns=['product_choices_text_raw'])\n",
        "    print(\"DataFrame หลังแปลง 'product_choices_text_raw':\")\n",
        "    print(df_processed.head())\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "KCleWl99vclP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. การคัดเลือกและลบคอลัมน์ที่ไม่จำเป็น ---\n",
        "# --- แสดงผลลัพธ์สุดท้ายของ DataFrame ที่พร้อมสำหรับ Model ---\n",
        "print(\"\\n--- ผลลัพธ์สุดท้าย: DataFrame พร้อมสำหรับ Train Model ---\")\n",
        "print(\"\\nDataFrame Head (ตัวอย่าง 5 แถวแรก):\")\n",
        "print(df_processed.head())\n",
        "\n",
        "print(\"\\nDataFrame Info (ข้อมูลสรุปประเภทข้อมูลและจำนวน Non-Null):\")\n",
        "df_processed.info()\n",
        "\n",
        "print(\"\\n--- รายชื่อคอลัมน์ (Feature Names) ทั้งหมดที่พร้อมสำหรับ Model ---\")\n",
        "# แสดงชื่อคอลัมน์ทั้งหมดเพื่อดูภาพรวมของ Features\n",
        "print(df_processed.columns.tolist())"
      ],
      "metadata": {
        "id": "-DJG7r3Mvjlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "Kwc_iAFKHlMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_processed.drop(columns=['join_next_year_Yes', 'join_next_year_No']) # ลบคอลัมน์ Target และ Dummy ที่เหลือ\n",
        "y = df_processed['join_next_year_Yes']\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5_tHR8Fx-NmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตัวอย่าง: ใช้ Logistic Regression\n",
        "model_lr = LogisticRegression(random_state=42, solver='liblinear') # solver='liblinear' เหมาะกับ dataset ขนาดเล็ก-กลาง\n",
        "model_lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yJDFEK2TxQik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lr = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "kmih17aMx7ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สำหรับ Logistic Regression\n",
        "print(\"--- Logistic Regression ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
        "\n",
        "# ถ้าต้องการ ROC AUC (ต้องใช้ predict_proba)\n",
        "if hasattr(model_lr, \"predict_proba\"):\n",
        "    y_prob_lr = model_lr.predict_proba(X_test)[:, 1]\n",
        "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob_lr):.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7uCcwoJ-xn1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตัวอย่าง: ใช้ Random Forest Classifier\n",
        "model_rf = RandomForestClassifier(random_state=42, n_estimators=100) # n_estimators คือจำนวนต้นไม้\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nMYjq5Y_vZGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = model_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "BYya8bbivZEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ทำซ้ำสำหรับ Random Forest (หรือโมเดลอื่นๆ)\n",
        "print(\"\\n--- Random Forest ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
        "\n",
        "if hasattr(model_rf, \"predict_proba\"):\n",
        "    y_prob_rf = model_rf.predict_proba(X_test)[:, 1]\n",
        "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob_rf):.4f}\")\n",
        "\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.title('Confusion Matrix - Random Forest')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdIjXsCDxrYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตัวอย่าง: ปรับจูน Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=3, # ใช้ 3-fold cross-validation\n",
        "                              scoring='f1', # หรือ 'roc_auc', 'accuracy'\n",
        "                              n_jobs=-1, # ใช้ทุก core ของ CPU\n",
        "                              verbose=1)\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Hyperparameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "print(\"Best F1-Score for Random Forest:\", grid_search_rf.best_score_)\n",
        "\n",
        "# โมเดลที่ดีที่สุดหลังการจูน\n",
        "best_model_rf = grid_search_rf.best_estimator_\n",
        "y_pred_best_rf = best_model_rf.predict(X_test)\n",
        "f1_rf_manual = f1_score(y_test, y_pred_best_rf)\n",
        "print(\"F1-Score on Test Set (Best RF):\", f1_score(y_test, y_pred_best_rf))"
      ],
      "metadata": {
        "id": "yTjkCJMAxcOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Auto ML"
      ],
      "metadata": {
        "id": "fhWznfmv21Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y"
      ],
      "metadata": {
        "id": "L3h1V_q020v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4 -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gJnQ6sbR24sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pycaret -y"
      ],
      "metadata": {
        "id": "7QiN72rr3Wno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret[full] --q --upgrade"
      ],
      "metadata": {
        "id": "RzZqybJ23DEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ก่อนอื่น ตรวจสอบให้แน่ใจว่าได้รันโค้ดส่วนการเตรียมข้อมูลทั้งหมดแล้ว\n",
        "# และ df_processed ได้ถูกสร้างขึ้นเรียบร้อย\n",
        "# โดย df_processed ควรเป็น DataFrame ที่ไม่มีคอลัมน์ 'id' และคอลัมน์ข้อความดิบอื่นๆ แล้ว\n",
        "# และมีคอลัมน์เช่น 'c21_no_opinion' และ 'pref_food', 'product_สินค้าบริโภค' เป็นต้น\n",
        "\n",
        "# --- Import PyCaret ---\n",
        "from pycaret.classification import *\n",
        "\n",
        "# --- เตรียมข้อมูลสำหรับ PyCaret ---\n",
        "# เราจะใช้ df_processed เป็นข้อมูลตั้งต้น\n",
        "# และ 'join_next_year_Yes' เป็นคอลัมน์เป้าหมาย\n",
        "# คอลัมน์ 'join_next_year_No' จะต้องถูกลบออกไปจากข้อมูลที่จะส่งให้ PyCaret\n",
        "# เนื่องจากมันเป็นตัวแทนของอีกคลาสหนึ่งของ Target และจะทำให้เกิด Multicollinearity\n",
        "# (คล้ายกับที่เรา drop 'join_next_year_No' จาก X ในการสร้างโมเดลเอง)\n",
        "data_for_pycaret = df_processed.copy()\n",
        "if 'join_next_year_No' in data_for_pycaret.columns:\n",
        "    data_for_pycaret = data_for_pycaret.drop(columns=['join_next_year_No'])\n",
        "    print(\"Dropped 'join_next_year_No' from data_for_pycaret as it's redundant with the target.\")\n",
        "\n",
        "\n",
        "# --- เรียกใช้งาน setup ของ PyCaret ---\n",
        "# PyCaret จะจัดการการแบ่งข้อมูล (train/test split), Preprocessing (scaling, encoding ที่เหลือ),\n",
        "# และจัดการค่าที่หายไป (ถ้ามี) ให้โดยอัตโนมัติ\n",
        "# ระบุ session_id เพื่อให้ผลลัพธ์ repeatable\n",
        "# คุณสามารถเพิ่ม normalize=True หรือ feature_selection=True หรือ parameters อื่นๆ ได้\n",
        "# เพื่อให้ PyCaret ทำ preprocessing เพิ่มเติม\n",
        "clf = setup(\n",
        "    data=data_for_pycaret,\n",
        "    target='join_next_year_Yes', # ระบุคอลัมน์ Target ที่ถูกต้อง\n",
        "    session_id=123,\n",
        "    # normalize = True, # ลองใช้ Normalization (StandardScaler)\n",
        "    # feature_selection = True, # ลองให้ PyCaret เลือก Features ที่สำคัญให้\n",
        "    # fix_imbalance = True # หาก Target Class ไม่สมดุล ลองเปิดใช้\n",
        "    # silent = True # หากต้องการซ่อน output ระหว่าง setup\n",
        ")\n",
        "\n",
        "# --- เปรียบเทียบโมเดลทั้งหมดและเลือกโมเดลที่ดีที่สุด ---\n",
        "# PyCaret จะรันโมเดล Classification ยอดนิยมหลายตัว\n",
        "# และเปรียบเทียบประสิทธิภาพโดยใช้ Cross-Validation\n",
        "# โดย default จะใช้ 'Accuracy' เป็น metric หลักในการเลือก แต่สามารถเปลี่ยนได้\n",
        "# เช่น compare_models(sort='F1')\n",
        "best_model = compare_models(sort='F1') # เราใช้ F1-Score ในการประเมินโมเดลของคุณเอง จึงควรใช้ F1 สำหรับ PyCaret ด้วย\n",
        "\n",
        "print(\"\\n--- Best Model from PyCaret ---\")\n",
        "print(best_model)\n",
        "\n",
        "# คุณยังสามารถเข้าถึง evaluation metrics ของ best_model ได้\n",
        "# predict_model(best_model, data=data_for_pycaret) # เพื่อดู performance บน full data\n",
        "# evaluate_model(best_model) # เพื่อดู plots ต่างๆ เช่น Confusion Matrix, ROC Curve\n",
        "\n",
        "# ถ้าต้องการสร้างโมเดลใดๆ ที่ PyCaret เปรียบเทียบแล้ว (เช่น 'lightgbm')\n",
        "# lgbm_model = create_model('lightgbm')\n",
        "# tuned_lgbm = tune_model(lgbm_model, optimize='F1')"
      ],
      "metadata": {
        "id": "XliKlqZP155m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# เปรียบเทียบโมเดลทั้งหมดและเลือกโมเดลที่ดีที่สุด\n",
        "best_model_pycaret_table = compare_models(sort='F1', verbose=False) # ใช้ verbose=False เพื่อไม่ให้แสดงตารางใหญ่\n",
        "# เราต้องการ F1-Score ของโมเดลที่ดีที่สุดจาก PyCaret (CatBoost)\n",
        "# ซึ่งสามารถดึงได้จากตารางที่ compare_models สร้างขึ้น (แต่เราต้องรับค่าเต็มของตาราง)\n",
        "# ถ้าต้องการ F1 ของ CatBoost โดยเฉพาะ\n",
        "best_f1_pycaret = pull()['F1'][0] # ดึงตารางแล้วเอาค่า F1 ของแถวแรก (ซึ่งคือ best model)\n",
        "best_model_name_pycaret = pull()['Model'][0] # ดึงชื่อโมเดลที่ดีที่สุด\n",
        "\n",
        "print(f\"Best Model from PyCaret: {best_model_name_pycaret}\")\n",
        "print(f\"F1-Score on Test Set (Best PyCaret Model - Cross-Validation Average): {best_f1_pycaret:.4f}\")"
      ],
      "metadata": {
        "id": "lG0XBK-z7SY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้าง DataFrame เพื่อเปรียบเทียบ\n",
        "comparison_data = {\n",
        "    'Model Source': ['Manual (Your Tuned RF)', 'AutoML (PyCaret Best Model)'],\n",
        "    'Model Name': ['Random Forest', best_model_name_pycaret],\n",
        "    'F1-Score': [f1_rf_manual, best_f1_pycaret]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n--- Model Comparison Summary ---\")\n",
        "print(comparison_df.to_string(index=False)) # ใช้ to_string(index=False) เพื่อไม่แสดง index\n",
        "\n",
        "# --- 7. สรุปผล ---\n",
        "\n",
        "print(\"\\n--- Conclusion ---\")\n",
        "if f1_rf_manual > best_f1_pycaret:\n",
        "    print(f\"The manually tuned Random Forest model performed slightly better with an F1-Score of {f1_rf_manual:.4f}.\")\n",
        "    print(f\"The AutoML (PyCaret) best model, {best_model_name_pycaret}, achieved an F1-Score of {best_f1_pycaret:.4f}.\")\n",
        "    print(\"\\nThis suggests that your in-depth understanding and manual tuning were highly effective for this dataset.\")\n",
        "elif best_f1_pycaret > f1_rf_manual:\n",
        "    print(f\"The AutoML (PyCaret) best model, {best_model_name_pycaret}, performed better with an F1-Score of {best_f1_pycaret:.4f}.\")\n",
        "    print(f\"Your manually tuned Random Forest model achieved an F1-Score of {f1_rf_manual:.4f}.\")\n",
        "    print(\"\\nThis indicates that AutoML efficiently found a superior model (CatBoost) that you might not have considered initially, showcasing its strength in broad model exploration.\")\n",
        "else:\n",
        "    print(f\"Both your manually tuned Random Forest model and the AutoML (PyCaret) best model ({best_model_name_pycaret}) achieved very similar F1-Scores of {f1_rf_manual:.4f}.\")\n",
        "    print(\"\\nThis suggests that both approaches are highly effective for this dataset.\")\n",
        "\n",
        "print(\"\\nOverall, this comparison highlights the strengths of both human expertise in deep tuning and AutoML's ability to efficiently explore a wide range of models.\")"
      ],
      "metadata": {
        "id": "n1wsJV6R7SQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# การหา Feature Importance ของ Random Forest ---\n",
        "importances = best_model_rf.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "\n",
        "# จัดเรียงตามความสำคัญจากมากไปน้อย\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n--- Feature Importance from Manual Random Forest Model ---\")\n",
        "print(feature_importance_df.head(10).to_string(index=False)) # แสดง 10 อันดับแรก\n",
        "\n",
        "# พล็อต Feature Importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20)) # แสดง 20 อันดับแรกในกราฟ\n",
        "plt.title('Top 20 Feature Importances from Random Forest')\n",
        "plt.xlabel('Importance (MDI)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D_tXnRguC4KE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}